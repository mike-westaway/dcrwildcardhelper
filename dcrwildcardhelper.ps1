# Enable strict mode to enforce variable declaration
Set-StrictMode -Version Latest

# In testing mode speed things up by not calling run-command first time
$IsTestingMode = $true

# Define the Linux paths
#$linuxPaths = @(
#    "/home/*/.bash_history",
#    "/etc",
#    "/var/log/waagent*.log"
#)

# these are the RegEx equivalents of the original Splunk wildcards
# Splunk wildcards are proprietary as are DCR wildcards
# for example Splunk '/var/.../*.log' becomes '/var/.*/[^/]+.log' in RegEx and '/var/myparentfolder/myfolder*/*.log in DCR (multiple potentially required) 
# for example Splunk '/var/*/*.log' becomes '/var/[^/]+/[^/]+.log' in RegEx and '/var/myfolder*/*.log' in DCR (multiple potentially required)
$linuxAzureSplunkWildcardPatterns = @(
    "/var/log/waagent*.log"
)

$linuxArcSplunkWildcardPatterns = @(
    "/var/log/azure/run-command-handler/handler*.log"
)

# Define the Windows paths
$windowsArcSplunkWildcardPatterns = @(
    "C:\ProgramData\AzureConnectedMachineAgent\Log\arcproxy*.log"
)

# location for the DCRs
$dcrLocation = "uksouth"
# storage account for scripts and script logs
$scriptStorageAccount = "arcserversukssa"
# container name for scripts and script logs
$scriptContainerName = "scripts"

# TODO make this a parameter
$dcrResourceGroup = "arc-servers-uks"

$sleepTime = 60       # seconds to wait between retries
$maxRetries = 30      # max number of retries

# SubscrioptionId, ResourceGroup, VM Name, DCE Name, Workspace Name, Table Name
$arcWindowsVMs = ,@(
    @("862097ad-4b0b-4f09-b98c-bfd14930e1b4", "My-Sql-Server", "LAPTOP-JF9KNPOJ", "arc-servers-uks-endpoint", "arc-servers-uks-law", "LinuxTextLogs2_CL")    
)

# SubscrioptionId, ResourceGroup, VM Name, DCE Name, Workspace Name, Table Name
$arcLinuxVMs = ,@(
    @("862097ad-4b0b-4f09-b98c-bfd14930e1b4", "arc-servers-uks", "LAPTOP-JF9KNPOJ", "arc-servers-uks-endpoint", "arc-servers-uks-law", "LinuxTextLogs2_CL")
)

# SubscrioptionId, ResourceGroup, VM Name, DCE Name, Workspace Name, Table Name
$azureWindowsVMs = ,@(
    @("862097ad-4b0b-4f09-b98c-bfd14930e1b4", "ai-foundry-byo-demo", "jumpbox", "arc-servers-uks-endpoint", "arc-servers-uks-law", "WindowsEvent_CL")    
)

# SubscrioptionId, ResourceGroup, VM Name, DCE Name, Workspace Name, Table Name
$azureLinuxVMs = ,@(
    @("862097ad-4b0b-4f09-b98c-bfd14930e1b4", "jumpbox-linux-uks", "jumpbox-linux", "arc-servers-uks-endpoint", "arc-servers-uks-law", "LinuxTextLogs2_CL")    
)

function Convert-SplunkWildcardToRegex {
    param (
        [Parameter(Mandatory = $true)]
        [string]$Pattern,
        [Parameter(Mandatory = $true)]
        [bool]$IsLinuxVm = $true
    )

    # Replace escaped Splunk wildcards with regex equivalents
    $regexPattern = $Pattern -replace '\.\.\.', '.*'      # '...' → '.*'

    if ($IsLinuxVm -eq $true) {
        $regexPattern = $regexPattern -replace '\*', '[^/]+'      # '*' → '[^/]+'
    }
    else {
        # double backslashes for Windows
        $regexPattern = $regexPattern -replace '\\', '\\'      # '\' → '\\'
        $regexPattern = $regexPattern -replace '\*', '[^\\]+'      # '*' → '[^/]+'
    }

    # Return the final regex pattern
    return $regexPattern
}

# Make a name from a wildcard path by stripping out any wildcard characters
# and prepending dcr_ to the name
function Get-DcrNameFromWildcard {
    param (
        [string]$WildcardPathname
    )

    $dcrName = $WildcardPathname -replace '[\*\?\[\]\^\.\:\\/]', '_'
    $dcrName = "dcr_" + $dcrName
    return $dcrName
}

# Get the DCR Folder Path for a given VM Resource Id and Folder
function Get-DcrFolderPath {
    param (
        [string]$VmResourceId,
        [string]$Folder
    )

    $retDcrFolderPath = $null

    # Is there a DCR Association for this VM
    $dcrAssociationArr = @(Get-AzDataCollectionRuleAssociation -ResourceUri $VmResourceId)

    foreach ($dcrAssociation in $dcrAssociationArr) {
        $dcrId = $dcrAssociation.DataCollectionRuleId

        if ($null -eq $dcrId) {
            Write-Host "DCR for Assoc. $($dcrAssociation.Name) does not exist - skipping" -ForegroundColor Yellow
            continue
        }

        $dcr = Get-AzResource -ResourceId $dcrId

        # Get the Data Sources from the DCR   
        $logFileDataSourceArr = @($dcr.Properties.dataSources.logFiles) 
        
        foreach ($logFileDataSource in $logFileDataSourceArr) {

            foreach ($filePattern in $logFileDataSource.filePatterns) {
                Write-Host "Checking DCR File Pattern: $filePattern for VM $machine" -ForegroundColor Magenta

                # if there are wildcards in the pattern then extract the folder part
                # else the pattern is a folder only
                if ($filePattern -match '[\*\?\[\.]') {
                    $retDcrFolderPath = $filePattern.Substring(0, $filePattern.LastIndexOf('/'))
                }
                else {
                    $retDcrFolderPath = $filePattern
                }

                if ($retDcrFolderPath -eq $Folder) {
                    Write-Host "Found matching DCR File Pattern" -ForegroundColor Green
                    return $retDcrFolderPath
                }                       
            }
        }
    }

    return $retDcrFolderPath
}

function New-DcrDataSourceAndAssociation {
    param (
        [Parameter(Mandatory = $false)]
        [AllowNull()]
        [object]$dcrName,
        [Parameter(Mandatory = $true)]
        [string]$DcrFilePattern,
        [Parameter(Mandatory = $true)]
        [string]$vmResourceId
        )

    $retDcrResource = $null
    
    $dcrResource = Get-AzResource -ResourceGroupName $dcrResourceGroup `
                    -ResourceType "microsoft.insights/datacollectionrules" `
                    -Name $dcrName `
                    -ErrorAction SilentlyContinue

    if ($null -eq $dcrResource) {
        Write-Host "DCR $dcrName does not exist - creating it" -ForegroundColor Yellow
        # create the DCR if it does not exist
        $dcr = New-DcrFromWildcard `
            -dcrName $dcrName `
            -dcrResourceGroupName $dcrResourceGroup `
            -dcrSubscriptionId $subscriptionId `
            -dcrLocation $dcrLocation `
            -dceName $dceName `
            -customLogPath $dcrFilePattern `
            -tableName $tableName `
            -workspaceName $workspaceName

        $retDcrResource = Get-AzResource -ResourceId $dcr.Id
    }
    else {
        # create the new Data Source
        $incomingStream = "Custom-Stream"                 # incoming stream name
        $dataSourceName = $DcrFilePattern + "-logfile"   # friendly name for this data source

        # Cannot have more than one Data Source object of a given type (eg Log File)
        # So in this case need to add an extra File Pattern to an exisiting data source object
        if ($null -ne $dcrResource.Properties.dataSources.logFiles) {
            # the Log Files data source already exists - recreate the object appending the new file pattern
            $exisitingDataSourceLogFiles = $dcrResource.Properties.dataSources.logFiles[0]

            $newFilePatterns = $exisitingDataSourceLogFiles.filePatterns + @($DcrFilePattern)

            $dcrDataSource = New-AzLogFilesDataSourceObject `
                -Name $exisitingDataSourceLogFiles.name  `
                -FilePattern $newFilePatterns `
                -Stream $exisitingDataSourceLogFiles.streams[0]
        }
        else {
            $dcrDataSource = New-AzLogFilesDataSourceObject `
                -Name $dataSourceName  `
                -FilePattern $DcrFilePattern `
                -Stream $incomingStream
        }

        # attach this to the exisiting DCR
        $null = Update-AzDataCollectionRule `
            -Name $dcrResource.Name `
            -ResourceGroupName $dcrResource.ResourceGroupName `
            -SubscriptionId $dcrResource.SubscriptionId `
            -DataSourceLogFile  $dcrDataSource 
            
        $retDcrResource = $dcrResource
    }


    # create the DCR Association
    $null = New-AzDataCollectionRuleAssociation `
        -AssociationName $retDcrResource.properties.dataSources.logFiles[0].name `
        -ResourceUri $vmResourceId `
        -DataCollectionRuleId $retDcrResource.ResourceId

    return $retDcrResource
}

        # Create a DCR based on a name
function New-DcrFromWildcard {
    param (
        [string]$dcrName,
        [string]$dcrResourceGroupName,
        [string]$dcrSubscriptionId,
        [string]$dcrLocation,
        [string]$dceName,
        [string]$customLogPath,
        [string]$tableName,
        [string]$workspaceName
    )

    $dceId = "/subscriptions/$dcrSubscriptionId/resourceGroups/$dcrResourceGroupName/providers/Microsoft.Insights/dataCollectionEndpoints/$dceName"
    $kind = "Linux"

    # Lookup Workspace Resource Id based on its Id
    $workspaceResourceId = "/subscriptions/$dcrSubscriptionId/resourcegroups/$dcrResourceGroupName/providers/microsoft.operationalinsights/workspaces/$workspaceName"

    # Create DCR payload
    $dcrPayload = @{
        name = $dcrName
        location = $dcrLocation
        kind = $kind
        properties = @{
            dataCollectionEndpointId = "$dceId"
            streamDeclarations = @{
                "Custom-Text-$tableName" = @{
                    columns = @(
                        @{ "name" = "TimeGenerated"; "type" = "datetime" }
                        @{ "name" = "RawData"; "type" = "string" }
                        @{ "name" = "FilePath"; "type" = "string" }
                        @{ "name" = "Computer" ; "type" = "string" }
                    )
                }
            }
            dataSources = @{
                logFiles = @(  # Changed from fileLogs
                    @{
                        streams = @("Custom-Text-$tableName")
                        filePatterns = @($customLogPath)
                        format = "text"
                        settings = @{ "text" = @{ "recordStartTimestampFormat" = "ISO 8601" } }
                        name = "Custom-Text-$tableName"
                    }
                )
            }
            destinations = @{
                logAnalytics = @(
                    @{
                        workspaceResourceId = $workspaceResourceId
                        name = $dcrName
                    }
                )
            }
            dataFlows = @(
                @{
                    streams = @("Custom-Text-$tableName")
                    destinations = @($dcrName)
                    transformKql = "source | extend TimeGenerated, RawData, Computer, FilePath"
                    outputStream = "Custom-$tableName"
                }
            )
        }
    }

    $payload = $dcrPayload | ConvertTo-Json -depth 10
    
    # Deploy DCR
    $retDcr = New-AzDataCollectionRule `
        -Name "$dcrName" `
        -ResourceGroupName "$dcrResourceGroupName" `
        -JsonString $payload

    return $retDcr
}

# helper function to get the anchor from a wildcard folde pattern
# ie the base folder before any wildcards
# example: Get-AnchorFromWildcard -SplunkWildcardPathname "/home/*/.bash_history" returns "/home"
function Get-AnchorFromWildcard {
    param (
        [string]$SplunkWildcardPathname,
        [bool]$IsLinuxVm
    )

    # Build an "anchor": everything before the first segment that contains a wildcard (* ? [)
    if ($IsLinuxVm -eq $true) {
        # Convert Windows path to use '/' for easier processing
        $segments = $SplunkWildcardPathname -split '/'
    }
    else {
        # Ensure Windows path uses '\' (it should already)
       $segments = $SplunkWildcardPathname -split '\\'
    }
    
    $anchorSegments = @()
    $sawWildcard = $false
    foreach ($seg in $segments) {
        if ($seg -match '[\*\?\[\.]') { $sawWildcard = $true; break }
        if ($seg -ne '') { $anchorSegments += $seg }
    }

    if ($IsLinuxVm) {
        # If the pattern starts with '/', keep it in the anchor for correct matching
        $leadingSlash = $SplunkWildcardPathname.StartsWith('/')

        $anchor = ($anchorSegments -join '/')
        if ($leadingSlash) { $anchor = "/$anchor" }
    }
    else {
        $anchor = ($anchorSegments -join '\')
    }

    return $anchor
}

# helper function to get the first matching wildcard pattern (converted to a DCR FilePattern) for a given folder
# for example if the Folder parameter is '/var/log' 
# and that matches the RegEx wildcard path '/var/[^/]+]/[^/]+.log' then return what DCR can process:
# the folder + globbed filename pattern. that is: '/var/log/*.log' 
function Get-FirstDcrFilePattern { 
    param (
        [string]$Folder,
        [array]$splunkWildcardPaths,
        [bool]$IsLinuxVm
    )

    foreach ($item in $splunkWildcardPaths) {
        # eg '/var/.../*.log' becomes '/var/.*/[^/]+.log'
        $regexPattern = Convert-SplunkWildcardToRegex -Pattern $item -IsLinuxVm $IsLinuxVm

        # eg '/*.log'
        if ($IsLinuxVm -eq $true) {
            $splunkPatternFileName = $item.Substring($item.LastIndexOf('/'))
        }
        else {
            $splunkPatternFileName = $item.Substring($item.LastIndexOf('\'))
        }

        # eg '/var/log' + '/*.log'
        $dcrFilePattern = $Folder + $splunkPatternFileName
        
        # eg '/var/log/*.log' matches '/var/[^/]+/[^/]+.log'
        if ($dcrFilePattern -match $regexPattern) {
            return $dcrFilePattern
        }
    }
    return $null
}

# helper function to build the script that will be executed on the VM
function Get-IngestScriptLinux {
    param (
        [bool]$isArcConnectedMachine,
        [string]$scriptStorageAccount,
        [string]$LogFilePath,
        [string]$tableName,
        [string]$dcrImmutableId,
        [string]$dceEndpointId,
        [string]$timestampColumn,
        [string]$timespan,
        [string]$scriptContainerName,
        [string]$workspaceId,
        [string]$VMName,
        [int]$sleepTime,
        [int]$maxRetries
    )

    if ($isArcConnectedMachine -eq $true) {
        $imdsHost = "localhost:40342"
    }
    else {
        $imdsHost = "169.254.169.254"
    }
    
    $script = @"
echo "Part I Get Access Token"
API_VERSION="2020-06-01"
RESOURCE="https://storage.azure.com/"
IDENTITY_ENDPOINT="http://$imdsHost/metadata/identity/oauth2/token"
ENDPOINT="`${IDENTITY_ENDPOINT}?resource=`${RESOURCE}&api-version=`${API_VERSION}"
"@

    # this ensures the next chunk starts on a new line
    $script += "`n"

    if ($isArcConnectedMachine -eq $true) {
        $script += @"
WWW_AUTH_HEADER=`$(curl -s -D - -o /dev/null -H "Metadata: true" "`$ENDPOINT" | grep -i "WWW-Authenticate")
SECRET_FILE=`$(echo `$WWW_AUTH_HEADER | awk -F 'Basic realm=' '{print `$2}' | sed 's/\r$//')
if [[ ! -f "`$SECRET_FILE" ]]; then echo "Error 2" && exit 1; fi
SECRET=`$(cat "`$SECRET_FILE")
RESPONSE=`$(curl -s -H "Metadata: true" -H "Authorization: Basic `$SECRET" "`$ENDPOINT")
"@
    }
    else {
        $script += @"
RESPONSE=`$(curl -s -H "Metadata: true" "`$ENDPOINT")`
"@
    }

    # this ensures the next chunk starts on a new line
    $script += "`n"

    $script += @"
ACCESS_TOKEN=`$(echo "`$RESPONSE" | sed -n 's/.*"access_token"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
if [ -n "`$ACCESS_TOKEN" ]; then echo "`$ACCESS_TOKEN"; else echo "Error 003 `$RESPONSE" && exit 1; fi
echo "Part II Download script"
storage_account=$scriptStorageAccount
container_name=$scriptContainerName
source_log_file=$LogFilePath
target_table=$tableName
dcr_immutable_id=$dcrImmutableId
endpoint_uri=$dceEndpointId
timestamp_column=$timestampColumn
time_span=$timespan
blob_name="waitForLogsAndIngest.sh"
local_file="waitForLogsAndIngest.sh"
workspace_id=$workspaceId
computer_name=$VMName
is_arc_connected_machine=$isArcConnectedMachine
sleep_time=$sleepTime
max_retries=$maxRetries
blob_url="https://`${storage_account}.blob.core.windows.net/`${container_name}/`${blob_name}"
curl -H "Authorization: Bearer `$ACCESS_TOKEN" -H "x-ms-version: 2020-10-02" "`$blob_url" -o "`$local_file"
chmod +x "`$local_file"
sed -i 's/\r$//' "./`$local_file"
bash "./`$local_file" `$workspace_id `$computer_name `$source_log_file `$target_table `$dcr_immutable_id `$endpoint_uri `$timestamp_column `$time_span `$is_arc_connected_machine `$sleep_time `$max_retries > "`${local_file%.sh}.log" 2>&1
echo "Part III Upload log file"
log_blob_name="`${blob_name%.sh}.log"
log_blob_url="https://`${storage_account}.blob.core.windows.net/`${container_name}/`${log_blob_name}"
curl -X PUT -H "Authorization: Bearer `$ACCESS_TOKEN" -H "x-ms-version: 2020-10-02" -H "x-ms-blob-type: BlockBlob" --data-binary @"`${local_file%.sh}.log" "`$log_blob_url"
"@

    return $script
}

# Refer to this article for how to get the access_token 
# https://learn.microsoft.com/en-us/azure/azure-arc/servers/managed-identity-authentication#acquiring-an-access-token-using-rest-api
function Get-IngestScriptWindows {
    param (
        [bool]$isArcConnectedMachine,
        [string]$scriptStorageAccount,
        [string]$LogFilePath,
        [string]$tableName,
        [string]$dcrImmutableId,
        [string]$dceEndpointId,
        [string]$timestampColumn,
        [string]$timespan,
        [string]$scriptContainerName,
        [string]$workspaceId,
        [string]$VMName,
        [int]$sleepTime,
        [int]$maxRetries
    )

    if ($isArcConnectedMachine -eq $true) {
        $imdsHost = "localhost:40342"
    }
    else {
        $imdsHost = "169.254.169.254"
    }
    
    $script = @"
echo "Part I Get Access Token"
`$API_VERSION = "2020-06-01"
`$RESOURCE = "https://storage.azure.com/"
`$IDENTITY_ENDPOINT = "http://$imdsHost/metadata/identity/oauth2/token"
`$ENDPOINT = "`${IDENTITY_ENDPOINT}?resource=`$RESOURCE&api-version=`$API_VERSION"
"@

    # this ensures the next chunk starts on a new line
    $script += "`n"

    if ($isArcConnectedMachine -eq $true) {
        $script += @"
try { (Invoke-WebRequest -Uri `$ENDPOINT -Headers @{Metadata='true'} -UseBasicParsing -ErrorAction Stop).Headers['WWW-Authenticate'] } catch { `$WWW_AUTH_HEADER = `$_.Exception.Response.Headers['WWW-Authenticate'] }
`$SECRET_FILE = (`$WWW_AUTH_HEADER -split 'Basic realm=')[1] -replace "`r$",""
if (-not (Test-Path `$SECRET_FILE)) { Write-Output "Error 2"; exit 1 }
`$SECRET=`$(cat "`$SECRET_FILE")
`$RESPONSE = Invoke-WebRequest -Method Get -Uri `$ENDPOINT -Headers @{Metadata='True'; Authorization="Basic `$SECRET"} -UseBasicParsing
"@
    }
    else {
        $script += @"
`$RESPONSE = Invoke-WebRequest -Method Get -Uri `$ENDPOINT -Headers @{Metadata='True'} -UseBasicParsing
"@
    }

    # this ensures the next chunk starts on a new line
    $script += "`n"

    $script += @"
`$ACCESS_TOKEN = (ConvertFrom-Json -InputObject `$RESPONSE.Content).access_token
if ([string]::IsNullOrWhiteSpace(`$ACCESS_TOKEN)) { Write-Output "Error 003 `$env:RESPONSE"; exit 1 }
echo "Part II Download script"
`$STORAGE_ACCOUNT = "$scriptStorageAccount"
`$CONTAINER_NAME = "$scriptContainerName"
`$SOURCE_LOG_FILE = "$LogFilePath"
`$TARGET_TABLE = "$tableName"
`$DCR_IMMUTABLE_ID = "$dcrImmutableId"
`$ENDPOINT_URI = "$dceEndpointId"
`$TIMESTAMP_COLUMN = "$timestampColumn"
`$TIME_SPAN = "$timespan"
`$BLOB_NAME = "waitForLogsAndIngest.ps1"
`$LOCAL_FILE = "waitForLogsAndIngest.ps1"
`$WORKSPACE_ID = "$workspaceId"
`$COMPUTER_NAME = "$VMName"
`$IS_ARC_CONNECTED_MACHINE = "$isArcConnectedMachine"
`$SLEEP_TIME = "$sleepTime"
`$MAX_RETRIES = "$maxRetries"
`$LOG_BLOB_NAME = (`$BLOB_NAME -replace '\.ps1$', '') + '.log'
`$BLOB_URL = "https://`${STORAGE_ACCOUNT}.blob.core.windows.net/`${CONTAINER_NAME}/`${BLOB_NAME}"
Invoke-WebRequest -Uri `$BLOB_URL -Headers @{ "Authorization" = "Bearer `$ACCESS_TOKEN"; "x-ms-version" = "2020-10-02" } -OutFile `$LOCAL_FILE
& "./`$LOCAL_FILE" -workspaceId "`$WORKSPACE_ID" -computerName "`$COMPUTER_NAME" -sourceLogFile "`$SOURCE_LOG_FILE" -targetTable "`$TARGET_TABLE" -dcrImmutableId "`$DCR_IMMUTABLE_ID" -endpointUri "`$ENDPOINT_URI" -timestampColumn "`$TIMESTAMP_COLUMN" -timeSpan "`$TIME_SPAN" -isArcConnectedMachine "`$IS_ARC_CONNECTED_MACHINE" -sleepTime "`$SLEEP_TIME" -maxRetries "`$MAX_RETRIES" > "`$LOG_BLOB_NAME"
echo "Part III Upload log file"
`$LOG_BLOB_URL = "https://`${STORAGE_ACCOUNT}.blob.core.windows.net/`${CONTAINER_NAME}/`${LOG_BLOB_NAME}"
Invoke-WebRequest -Uri `$LOG_BLOB_URL -Headers @{ "Authorization" = "Bearer `$ACCESS_TOKEN"; "x-ms-version" = "2020-10-02"; "x-ms-blob-type" = "BlockBlob" } -Method Put -InFile "`$LOG_BLOB_NAME"
"@

    return $script
}

# Get-IngestScript helper to choose Linux or Windows version
function Get-IngestScript {
    param (
        [bool]$isArcConnectedMachine,
        [string]$scriptStorageAccount,
        [string]$LogFilePath,
        [string]$tableName,
        [string]$dcrImmutableId,
        [string]$dceEndpointId,
        [string]$timestampColumn,
        [string]$timespan,
        [string]$scriptContainerName,
        [string]$workspaceId,
        [string]$VMName,
        [bool]$isLinuxVm
    )

    if ($isLinuxVm -eq $true) {
        return Get-IngestScriptLinux `
            -isArcConnectedMachine $isArcConnectedMachine `
            -scriptStorageAccount $scriptStorageAccount `
            -LogFilePath $LogFilePath `
            -tableName $tableName `
            -dcrImmutableId $dcrImmutableId `
            -dceEndpointId $dceEndpointId `
            -timestampColumn $timestampColumn `
            -timespan $timespan `
            -scriptContainerName $scriptContainerName `
            -workspaceId $workspaceId `
            -VMName $VMName
    }
    else {
        return Get-IngestScriptWindows `
            -isArcConnectedMachine $isArcConnectedMachine `
            -scriptStorageAccount $scriptStorageAccount `
            -LogFilePath $LogFilePath `
            -tableName $tableName `
            -dcrImmutableId $dcrImmutableId `
            -dceEndpointId $dceEndpointId `
            -timestampColumn $timestampColumn `
            -timespan $timespan `
            -scriptContainerName $scriptContainerName `
            -workspaceId $workspaceId `
            -VMName $VMName
    }
}


# Execute a run command on a VM based on whether it's Arc-connected and Linux/Windows
function RunCommand {
    param (
        [string]$ResourceGroupName,
        [string]$VMName,
        [string]$ScriptString,
        [bool]$IsArcConnectedMachine,
        [bool]$IsLinuxVm,
        [bool]$IsAsync = $false
    )

    # Create a key combining all three boolean states
    $caseKey = "$IsArcConnectedMachine-$IsLinuxVm-$IsAsync"

    switch ($caseKey) {
        # Arc + Linux + Async
        "True-True-True" {
            $result = New-AzConnectedMachineRunCommand `
                -ResourceGroupName $ResourceGroupName `
                -MachineName $VMName `
                -Location $dcrLocation `
                -RunCommandName "ArcRunCmd" `
                -SourceScript $ScriptString `
                -AsJob
        }
        # Arc + Linux + Sync
        "True-True-False" {
            $result = Invoke-AzConnectedMachineRunCommand `
                -ResourceGroupName $ResourceGroupName `
                -MachineName $VMName `
                -CommandId 'RunShellScript' `
                -ScriptString $ScriptString
        }
        # Arc + Windows + Async
        "True-False-True" {
            $result = New-AzConnectedMachineRunCommand `
                -ResourceGroupName $ResourceGroupName `
                -MachineName $VMName `
                -Location $dcrLocation `
                -RunCommandName "ArcRunCmd" `
                -SourceScript $ScriptString `
                -AsJob
        }
        # Arc + Windows + Sync
        "True-False-False" {
            $result = Invoke-AzConnectedMachineRunCommand `
                -ResourceGroupName $ResourceGroupName `
                -MachineName $VMName `
                -CommandId 'RunPowerShellScript' `
                -ScriptString $ScriptString
        }
        # Azure VM + Linux + Async
        "False-True-True" {
            $result = Invoke-AzVMRunCommand `
                -ResourceGroupName $ResourceGroupName `
                -VMName $VMName `
                -CommandId 'RunShellScript' `
                -ScriptString $ScriptString `
                -AsJob
        }
        # Azure VM + Linux + Sync
        "False-True-False" {
            $result = Invoke-AzVMRunCommand `
                -ResourceGroupName $ResourceGroupName `
                -VMName $VMName `
                -CommandId 'RunShellScript' `
                -ScriptString $ScriptString
        }
        # Azure VM + Windows + Async
        "False-False-True" {
            $result = Invoke-AzVMRunCommand `
                -ResourceGroupName $ResourceGroupName `
                -VMName $VMName `
                -CommandId 'RunPowerShellScript' `
                -ScriptString $ScriptString `
                -AsJob
        }
        # Azure VM + Windows + Sync
        "False-False-False" {
            $result = Invoke-AzVMRunCommand `
                -ResourceGroupName $ResourceGroupName `
                -VMName $VMName `
                -CommandId 'RunPowerShellScript' `
                -ScriptString $ScriptString
        }
    }

    return $result
}

# start an async run-command to monitor the target table and ingest any missing log file entries
function RunCommandAsyncToIngestMissingLogs {
    param (
        [string]$SubscriptionId,
        [string]$ResourceGroupName,
        [string]$VMName,
        [string]$DcrName,
        [string]$LogFilePath,
        [string]$scriptStorageAccount,
        [string]$scriptContainerName,
        [bool]$isArcConnectedMachine,
        [string]$dcrImmutableId,
        [string]$dceEndpointId,
        [string]$workspaceId,
        [string]$tableName,
        [string]$timestampColumn,
        [string]$timespan,
        [bool]$isLinuxVm,
        [int]$sleepTime,
        [int]$maxRetries
    )

    # TODO implement the function to run a command asynchronously to monitor the target table and ingest any missing log file entries
    Write-Host "Starting async command to monitor logs for VM $VMName, DCR $DcrName, Log File Path $LogFilePath" -ForegroundColor Blue

    # script outline:
    # 1. Get an access token for Storage
    # 2. Download scripts from storage to the VM
    # 3. Run the script
    ## 1. Determine the target Log Analytics workspace associated with the DCR
    ## 2. Start a background job or scheduled task on the VM to periodically check the Log Analytics workspace for new log entries from the specified log file path
    ## 3. Ingest any missing log file entries into the target table

    # this script is a compact version of getAccessToken.sh and downloadScriptFromStorage.sh
    # note the backticks prevent the bash variables from being expanded in PowerShell
    # note on Azure VM get a token with:
    # http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&resource=<resource>
    # where resource is eg https://storage.azure.com/
    # on Arc enabled connected machine, use:
    # http://localhost:40342/metadata/identity/oauth2/token?api-version=2020-06-01&resource=<resource>
    # on Azure linux curl -s -H "Metadata: true" "$ENDPOINT" returns JSON with access_token

    $script = Get-IngestScript `
        -isArcConnectedMachine $isArcConnectedMachine `
        -scriptStorageAccount $scriptStorageAccount `
        -LogFilePath $LogFilePath `
        -tableName $tableName `
        -dcrImmutableId $dcrImmutableId `
        -dceEndpointId $dceEndpointId `
        -timestampColumn $timestampColumn `
        -timespan $timespan `
        -scriptContainerName $scriptContainerName `
        -workspaceId $workspaceId `
        -VMName $VMName `
        -isLinuxVm $isLinuxVm `
        -sleepTime $sleepTime `
        -maxRetries $maxRetries

    $scriptOneLine = ($script -split "`r?`n" | Where-Object { $_.Trim() -ne "" }) -join ";"

    $job = RunCommand `
        -ResourceGroupName $ResourceGroupName `
        -VMName $VMName `
        -ScriptString $scriptOneLine `
        -IsArcConnectedMachine $isArcConnectedMachine `
        -IsLinuxVm $isLinuxVm `
        -IsAsync $true

    Write-Host "Started async job for pre ingestion with ID: $($job.Id)" -ForegroundColor Blue
}

function main {
    param (
        [Parameter(Mandatory = $true)]
        [array]$SplunkWildcardPaths,
        [Parameter(Mandatory = $true)]
        [array]$VmList,
        [Parameter(Mandatory = $true)]
        [System.Boolean]$IsArcConnectedMachine,
        [Parameter(Mandatory = $true)]
        [System.Boolean]$IsLinuxVm
    )


    foreach ($vm in $VmList) {
        $subscriptionId = $vm[0]
        $resourceGroup = $vm[1]
        $machine = $vm[2]
        $dceName = $vm[3]
        $workspaceName = $vm[4]
        $tableName = $vm[5]

        Set-AzContext -Subscription $subscriptionId

        Write-Host "Processing Azure Windows VM: $machine in Resource Group: $resourceGroup under Subscription: $subscriptionId" -ForegroundColor Green

        $cmdTemplateLinux = 'find $anchor -wholename "$path" $pipeline'
        $cmdTemplateWindows = 'Get-ChildItem -Path $anchor -Recurse -Force | Where-Object { $_.FullName -like "$path" } | Select-Object -ExpandProperty FullName'

        if ($IsLinuxVm -eq $false) {
            $cmdTemplate = $cmdTemplateWindows
        }
        else {
            $cmdTemplate = $cmdTemplateLinux
        }

        # make big command as run-command is expensive, so do once per server
        $cmds = ""
        foreach ($wildcardPath in $SplunkWildcardPaths) {
            $anchor = Get-AnchorFromWildcard -SplunkWildcardPathname $wildcardPath -IsLinuxVm $IsLinuxVm
            # if path contains a wildcard then use dirname to return the folder name only
            # else we already have the folder name eg /etc
            if ($wildcardPath -match '[\*\?\[\.]') {
                $pipeline = "| xargs -I {} dirname {} | sort -u"
            }
            else {
                $pipeline = "| sort -u"
            }
            $cmd = $cmdTemplate `
                -replace '\$anchor', $anchor `
                -replace '\$path', $wildcardPath `
                -replace '\$pipeline', $pipeline
            $cmds += $cmd + "; "
        }

        # create a runCommand function and pass in OS and IsOnPrem parameters
        # TODO error handling if the VM is not reachable
        $result = $null
        try {
            if ($IsTestingMode) {
                # Azure Linux test case
                #$resultArr = ,@('/var/log')
                # Arc Linux Test Case
                #$resultArr = ,@('/var/log/azure/run-command-handler')
                # Arc Windows Text case
                $resultArr = ,@('C:\ProgramData\AzureConnectedMachineAgent\Log')
                $sleepTime = 10
                $maxRetries = 3
            }
            else {
                $result = RunCommand `
                    -ResourceGroupName $resourceGroup `
                    -VMName $machine `
                    -ScriptString $cmds `
                    -IsArcConnectedMachine $IsArcConnectedMachine `
                    -IsLinuxVm $IsLinuxVm
            }
    
        }
        catch {
            Write-Host "Error executing Run Command on VM ${machine}: $_" -ForegroundColor Red
            continue
        }


        # convert the multiline string returned to an array
        # Value[0] is StdOut on Windows. 
        # On Linux I bleieve its all combined so just ignore results that do not start with a /
        if ($IsTestingMode -eq $false) {
            $resultArr = $result.Value[0].Message -split "`n"
        }

        # keep the unique entries in the array
        $resultArrUnique = $resultArr | Select-Object -Unique

        foreach ($folder in $resultArrUnique) {

            if ($IsLinuxVm -eq $false) {
                # filter out any non-windows folder paths
                if ($folder -notmatch "^[a-zA-Z]:\\") { continue }
            }
            else {
                # filter out any non-linux folder paths
                if ($folder -notlike "/*") { continue }
            }

            # lookup the first wildcard pattern and type associated with this folder
            $dcrFilePattern = Get-FirstDcrFilePattern -Folder $folder -splunkWildcardPaths $splunkWildcardPaths -IsLinuxVm $IsLinuxVm

            # if no matches log the error and continue
            if ($null -eq $dcrFilePattern) {
                Write-Host "No matching wildcard pattern found for folder $folder on VM $machine - skipping" -ForegroundColor Yellow
                continue
            }

            Write-Host "Wildcard paths found on ${machine}:" -ForegroundColor Yellow
            Write-Host $folder -ForegroundColor Cyan

            # Get the VM Resource Id
            if ($IsArcConnectedMachine -eq $true) {
                $vmResourceId = (Get-AzResource -ResourceGroupName $resourceGroup -ResourceName $machine -ResourceType "Microsoft.HybridCompute/machines").ResourceId
            }
            else {  
                $vmResourceId = (Get-AzResource -ResourceGroupName $resourceGroup -ResourceName $machine -ResourceType "Microsoft.Compute/virtualMachines").ResourceId
            }

            $dcrFolderPath = Get-DcrFolderPath -VmResourceId $vmResourceId -Folder $folder

            if ($null -eq $dcrFolderPath) {
                # lookup the Dcr Id based on the Resource Group and Name
                $dcrName  = $(Get-DcrNameFromWildcard $dcrFilePattern)

                $dcr = New-DcrDataSourceAndAssociation -DcrName $dcrName -DcrFilePattern $dcrFilePattern -vmResourceId $vmResourceId

                if ($dcr) {
                    # lookup the workspace immutable id based on the name and resourcegroup
                    $workspace = Get-AzOperationalInsightsWorkspace -ResourceGroupName $dcrResourceGroup -Name $workspaceName
                    $workspaceId = $workspace.CustomerId

                    # lookup the DCE endpoint
                    $dce = Get-AzResource -ResourceId $dcr.Properties.dataCollectionEndpointId

                    # output the command we are about to run into the log
                    Write-Host "Starting async command to monitor and ingest logs for VM $machine, DCR $dcrName, Log File Path $dcrFilePattern" -ForegroundColor Blue

                    # at this point we have the DCR, Data Source, Folder Path and Association created
                    # the detection of the new log file and the creation of the DCR plus time to first ingestion
                    # will take some time
                    # start an async run-command to monitor the target table and ingest any missing log file entries
                    RunCommandAsyncToIngestMissingLogs `
                    -SubscriptionId $subscriptionId `
                    -ResourceGroupName $resourceGroup `
                    -VMName $machine `
                    -DcrName $dcr.Name `
                    -LogFilePath $dcrFilePattern `
                    -scriptStorageAccount $scriptStorageAccount `
                    -scriptContainerName $scriptContainerName `
                    -isArcConnectedMachine $IsArcConnectedMachine `
                    -dcrImmutableId $dcr.Properties.immutableId `
                    -dceEndpointId $dce.Properties.logsIngestion.endpoint `
                    -WorkspaceId $workspaceId `
                    -tableName $tableName `
                    -timestampColumn "TimeGenerated" `
                    -timespan "P1D" `
                    -isLinuxVm $IsLinuxVm `
                    -sleepTime $sleepTime `
                    -maxRetries $maxRetries `
                }
            }
        }
    }
}

# entry point for Azure Linux VMs
#main -SplunkWildcardPaths $linuxAzureSplunkWildcardPatterns -VmList $azureLinuxVMs -IsArcConnectedMachine $false -IsLinuxVm $true

# Entry point for Arc Linux VMs
#main -SplunkWildcardPaths $linuxArcSplunkWildcardPatterns -VmList $arcLinuxVMs -IsArcConnectedMachine $true -IsLinuxVm $true

# Entry point for Arc Windows VMs
main -SplunkWildcardPaths $windowsArcSplunkWildcardPatterns -VmList $arcWindowsVMs -IsArcConnectedMachine $true -IsLinuxVm $false

